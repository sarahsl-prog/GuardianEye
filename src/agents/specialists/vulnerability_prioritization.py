"""Vulnerability Prioritization Agent for risk assessment."""

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

from src.agents.base.base_agent import BaseAgent, AgentInput, AgentOutput
from src.core.prompts import VULNERABILITY_PRIORITIZATION_PROMPT


class VulnerabilityPrioritizationAgent(BaseAgent):
    """Agent for prioritizing vulnerabilities based on risk."""

    def __init__(self, llm):
        """Initialize the Vulnerability Prioritization Agent."""
        super().__init__(llm, name="vulnerability_prioritization")

    def get_prompt_template(self) -> str:
        """Return the prompt template for this agent."""
        return VULNERABILITY_PRIORITIZATION_PROMPT

    async def process(self, input_data: AgentInput) -> AgentOutput:
        """Process vulnerability prioritization request."""
        vulnerabilities = input_data.context.get("vulnerabilities", input_data.query)

        prompt = ChatPromptTemplate.from_template(self.get_prompt_template())
        chain = prompt | self.llm | StrOutputParser()

        response = await chain.ainvoke({"vulnerabilities": vulnerabilities})

        return AgentOutput(
            result=response,
            metadata={
                "agent": self.name,
                "model": getattr(self.llm, "model_name", "unknown")
            }
        )
